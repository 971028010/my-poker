/**
 * å¾·å·æ‰‘å…‹ AI æ•™ç»ƒ - v11 OpenAI æ»¡è¡€ç‰ˆ
 */

const state = {
    apiKey: localStorage.getItem('openai_api_key') || '',
    isAnalyzing: false
};

function updateStatus(text) {
    const statusEl = document.getElementById('currentStatus');
    if (statusEl) statusEl.innerText = text;
}

window.onload = () => {
    const input = document.getElementById('openAIKey');
    // è‡ªåŠ¨å›å¡«ä¿å­˜çš„ Key
    if (state.apiKey) input.value = state.apiKey;
    
    // ç»‘å®šä¿å­˜æŒ‰é’®
    document.getElementById('saveKeys').onclick = () => {
        state.apiKey = input.value.trim();
        localStorage.setItem('openai_api_key', state.apiKey);
        updateStatus('âœ… OpenAI Key å·²æˆåŠŸä¿å­˜');
    };

    // ç»‘å®šå¼€å¯æ‘„åƒå¤´
    document.getElementById('startCamera').onclick = async () => {
        try {
            const stream = await navigator.mediaDevices.getUserMedia({ 
                video: { facingMode: 'environment', width: { ideal: 1280 } } 
            });
            document.getElementById('videoElement').srcObject = stream;
            document.getElementById('videoOverlay').classList.add('hidden');
            updateStatus('ğŸ“· æ‘„åƒå¤´å°±ç»ª');
        } catch (e) { 
            updateStatus('âŒ æ‘„åƒå¤´é”™è¯¯: ' + e.message); 
        }
    };

    // ç»‘å®šåˆ†ææŒ‰é’®
    document.getElementById('captureBtn').onclick = captureAndAnalyze;
    updateStatus('ğŸš€ ç³»ç»Ÿå‡†å¤‡å°±ç»ª-v11 (GPT-4o)');
};

async function captureAndAnalyze() {
    if (!state.apiKey) return alert('è¯·å…ˆè¾“å…¥ OpenAI API Key å¹¶ä¿å­˜');
    if (state.isAnalyzing) return;
    
    state.isAnalyzing = true;
    updateStatus('ğŸ” GPT-4o æ­£åœ¨è¯†å›¾å¹¶è®¡ç®—ç­–ç•¥...');

    const canvas = document.getElementById('captureCanvas');
    const video = document.getElementById('videoElement');
    
    // ç¡®ä¿ç”»å¸ƒå°ºå¯¸ä¸è§†é¢‘ä¸€è‡´
    canvas.width = video.videoWidth;
    canvas.height = video.videoHeight;
    canvas.getContext('2d').drawImage(video, 0, 0);
    
    // è½¬æ¢ä¸º OpenAI è¦æ±‚çš„ Base64 æ ¼å¼
    const base64Image = canvas.toDataURL('image/jpeg', 0.7);

    try {
        const response = await fetch('https://api.openai.com/v1/chat/completions', {
            method: 'POST',
            headers: { 
                'Content-Type': 'application/json',
                'Authorization': `Bearer ${state.apiKey}`
            },
            body: JSON.stringify({
                model: "gpt-4o",
                messages: [
                    {
                        role: "user",
                        content: [
                            { 
                                type: "text", 
                                text: "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å¾·å·æ‰‘å…‹ GTO æ•™ç»ƒã€‚è¯·è¯†åˆ«å›¾ä¸­çš„æ‰‹ç‰Œã€å…¬å…±ç‰Œå’Œåº•æ± ï¼Œç»™å‡ºå»ºè®®åŠ¨ä½œ(FOLD/CALL/CHECK/RAISE)åŠè¯¦ç»†çš„é€»è¾‘ç†ç”±ã€‚" 
                            },
                            { 
                                type: "image_url", 
                                image_url: { url: base64Image } 
                            }
                        ]
                    }
                ],
                max_tokens: 800
            })
        });

        const data = await response.json();
        
        if (data.error) {
            throw new Error(data.error.message);
        }

        // æ˜¾ç¤º AI çš„å›ç­”
        document.getElementById('analysisContent').innerText = data.choices[0].message.content;
        updateStatus('âœ… ç­–ç•¥ç”ŸæˆæˆåŠŸ');
    } catch (e) {
        console.error(e);
        updateStatus('âŒ å¤±è´¥: ' + e.message);
    } finally {
        state.isAnalyzing = false;
